{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "import hydra\n",
    "import lightning as pl\n",
    "from omegaconf import DictConfig\n",
    "from lightning import Callback, LightningDataModule, LightningModule, Trainer\n",
    "from lightning.pytorch.loggers import Logger\n",
    "\n",
    "from terralearn import utils\n",
    "\n",
    "import torch\n",
    "import hydra\n",
    "import omegaconf\n",
    "import pyrootutils\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/ubuntu/FGVC11_2024/data/PlantTrait/test.csv')\n",
    "df['path'] = '/home/ubuntu/FGVC11_2024/data/PlantTrait/test_images/' + df['id'].astype(str) + '.jpeg'\n",
    "# df.to_csv('/home/ubuntu/FGVC11_2024/data/PlantTrait/df_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = omegaconf.OmegaConf.load(\"/home/ubuntu/FGVC11_2024/configs/data/plant_traits_data.yaml\")\n",
    "datamodule: LightningDataModule = hydra.utils.instantiate(cfg)\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in datamodule.test_dataloader():\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ubuntu/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "/home/ubuntu/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "/home/ubuntu/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "/home/ubuntu/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n",
      "/home/ubuntu/miniconda3/envs/transformers/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:196: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "cfg = omegaconf.OmegaConf.load(\"/home/ubuntu/FGVC11_2024/configs/model/plant_traits_model.yaml\")\n",
    "model = hydra.utils.instantiate(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PlantTraitModule(\n",
       "  (model): PlantCNN(\n",
       "    (body): DinoVisionTransformer(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 384, kernel_size=(14, 14), stride=(14, 14))\n",
       "        (norm): Identity()\n",
       "      )\n",
       "      (blocks): ModuleList(\n",
       "        (0-11): 12 x NestedTensorBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MemEffAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (head): Identity()\n",
       "    )\n",
       "    (relu1): ReLU()\n",
       "    (fc1): Linear(in_features=384, out_features=192, bias=True)\n",
       "    (relu2): ReLU()\n",
       "    (fc2): Linear(in_features=192, out_features=6, bias=True)\n",
       "  )\n",
       "  (criterion): R2Loss()\n",
       "  (metrics): R2Score()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_from_checkpoint('/home/ubuntu/FGVC11_2024/logs/train/runs/2024-04-04_08-39-28/checkpoints/epoch_058.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PlantTraitModule(\n",
       "  (model): PlantCNN(\n",
       "    (body): DinoVisionTransformer(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 384, kernel_size=(14, 14), stride=(14, 14))\n",
       "        (norm): Identity()\n",
       "      )\n",
       "      (blocks): ModuleList(\n",
       "        (0-11): 12 x NestedTensorBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MemEffAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (head): Identity()\n",
       "    )\n",
       "    (relu1): ReLU()\n",
       "    (fc1): Linear(in_features=384, out_features=192, bias=True)\n",
       "    (relu2): ReLU()\n",
       "    (fc2): Linear(in_features=192, out_features=6, bias=True)\n",
       "  )\n",
       "  (criterion): R2Loss()\n",
       "  (metrics): R2Score()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 410/410 [00:50<00:00,  8.19it/s]\n"
     ]
    }
   ],
   "source": [
    "all_predictions = []\n",
    "for batch in tqdm(datamodule.test_dataloader()):\n",
    "    # Unpack the batch\n",
    "    images = batch[\"image\"]\n",
    "\n",
    "    # Move data to the device\n",
    "    images = images.to(device)\n",
    "\n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        predictions = model.forward(images)\n",
    "    # break\n",
    "\n",
    "    # Move predictions back to CPU if necessary\n",
    "    predictions = predictions.cpu().numpy()\n",
    "\n",
    "    # Append predictions to the list\n",
    "    all_predictions.append(predictions)\n",
    "\n",
    "# Concatenate predictions from all batches\n",
    "all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "\n",
    "# Create a DataFrame with the predictions and corresponding IDs\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': df['id'].values,\n",
    "    'X4': all_predictions[:, 0],\n",
    "    'X11': all_predictions[:, 1],\n",
    "    'X18': all_predictions[:, 2],\n",
    "    'X50': all_predictions[:, 4],\n",
    "    'X26': all_predictions[:, 3],\n",
    "    'X3112': all_predictions[:, 5],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 490, 490])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>X4</th>\n",
       "      <th>X11</th>\n",
       "      <th>X18</th>\n",
       "      <th>X50</th>\n",
       "      <th>X26</th>\n",
       "      <th>X3112</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.545000e+03</td>\n",
       "      <td>6545.000000</td>\n",
       "      <td>6545.000000</td>\n",
       "      <td>6545.000000</td>\n",
       "      <td>6545.000000</td>\n",
       "      <td>6545.000000</td>\n",
       "      <td>6545.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.930247e+08</td>\n",
       "      <td>0.289149</td>\n",
       "      <td>-0.181909</td>\n",
       "      <td>-0.279819</td>\n",
       "      <td>0.006340</td>\n",
       "      <td>-0.044360</td>\n",
       "      <td>-0.255776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.601377e+07</td>\n",
       "      <td>0.156600</td>\n",
       "      <td>0.153120</td>\n",
       "      <td>0.146321</td>\n",
       "      <td>0.157188</td>\n",
       "      <td>0.142666</td>\n",
       "      <td>0.156738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.040495e+06</td>\n",
       "      <td>-0.269778</td>\n",
       "      <td>-0.823464</td>\n",
       "      <td>-0.914760</td>\n",
       "      <td>-0.551631</td>\n",
       "      <td>-0.550513</td>\n",
       "      <td>-0.855559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.971690e+08</td>\n",
       "      <td>0.187059</td>\n",
       "      <td>-0.285264</td>\n",
       "      <td>-0.377304</td>\n",
       "      <td>-0.099288</td>\n",
       "      <td>-0.137000</td>\n",
       "      <td>-0.359471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.008276e+08</td>\n",
       "      <td>0.292193</td>\n",
       "      <td>-0.184891</td>\n",
       "      <td>-0.281518</td>\n",
       "      <td>0.005224</td>\n",
       "      <td>-0.040999</td>\n",
       "      <td>-0.253713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.022672e+08</td>\n",
       "      <td>0.393154</td>\n",
       "      <td>-0.080483</td>\n",
       "      <td>-0.181248</td>\n",
       "      <td>0.112426</td>\n",
       "      <td>0.054326</td>\n",
       "      <td>-0.150215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.030654e+08</td>\n",
       "      <td>0.951173</td>\n",
       "      <td>0.478563</td>\n",
       "      <td>0.255759</td>\n",
       "      <td>0.638275</td>\n",
       "      <td>0.413662</td>\n",
       "      <td>0.300938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id           X4          X11          X18          X50  \\\n",
       "count  6.545000e+03  6545.000000  6545.000000  6545.000000  6545.000000   \n",
       "mean   1.930247e+08     0.289149    -0.181909    -0.279819     0.006340   \n",
       "std    2.601377e+07     0.156600     0.153120     0.146321     0.157188   \n",
       "min    1.040495e+06    -0.269778    -0.823464    -0.914760    -0.551631   \n",
       "25%    1.971690e+08     0.187059    -0.285264    -0.377304    -0.099288   \n",
       "50%    2.008276e+08     0.292193    -0.184891    -0.281518     0.005224   \n",
       "75%    2.022672e+08     0.393154    -0.080483    -0.181248     0.112426   \n",
       "max    2.030654e+08     0.951173     0.478563     0.255759     0.638275   \n",
       "\n",
       "               X26        X3112  \n",
       "count  6545.000000  6545.000000  \n",
       "mean     -0.044360    -0.255776  \n",
       "std       0.142666     0.156738  \n",
       "min      -0.550513    -0.855559  \n",
       "25%      -0.137000    -0.359471  \n",
       "50%      -0.040999    -0.253713  \n",
       "75%       0.054326    -0.150215  \n",
       "max       0.413662     0.300938  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch.nn as nn\n",
    "class PlantCNN(nn.Module):\n",
    "    def __init__(self, num_targets=6):\n",
    "        super(PlantCNN, self).__init__()\n",
    "        self.train_tokens = False\n",
    "        self.trainable_backbone_layers = 4\n",
    "        self.body = torch.hub.load(\n",
    "            \"facebookresearch/dinov2\", \"dinov2_vits14_reg\", pretrained=True\n",
    "        )\n",
    "        for i, layer in enumerate([self.body.patch_embed, self.body.norm]):\n",
    "            for p in layer.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        if not self.train_tokens:\n",
    "            self.body.cls_token.requires_grad = False\n",
    "            self.body.pos_embed.requires_grad = False\n",
    "            self.body.register_tokens.requires_grad = False\n",
    "            self.body.mask_token.requires_grad = False\n",
    "\n",
    "        if self.trainable_backbone_layers is not None:\n",
    "            for i in range(0, len(self.body.blocks) - self.trainable_backbone_layers):\n",
    "                for p in self.body.blocks[i].parameters():\n",
    "                    p.requires_grad = False\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(\n",
    "            self.body.num_features, self.body.num_features // 2\n",
    "        )\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(self.body.num_features // 2, num_targets)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.body(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = PlantCNN().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchsummary.summary(model, (3, 490, 490))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
