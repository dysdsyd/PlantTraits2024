{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import hydra\n",
    "import omegaconf\n",
    "import pyrootutils\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from fgvc.data.plant_clef_data import PlantCLEFDataset, PlantSPECIESDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/ubuntu/FGVC11/data/PlantClef/PlantCLEFTrainLQ.csv\",  delimiter=\";\", escapechar=\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = df[\"species_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = df[\"path\"][df.species_id == species[30]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in images[:10]:\n",
    "    im = Image.open(img)\n",
    "    plt.imshow(im)\n",
    "    plt.show()\n",
    "    # brea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_df = pd.DataFrame(df.groupby('species_id')[\"learn_tag\"].value_counts())\n",
    "sp_df.columns = ['count']\n",
    "sp_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.species_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Species Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/ubuntu/FGVC11/data/PlantClef/le.pkl\", \"rb\") as f: \n",
    "    le = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = PlantSPECIESDataset(\n",
    "    df=df[df.learn_tag == \"train\"].reset_index(drop=True), \n",
    "    label_encoder=le,\n",
    "    transform=datamodule.transform,\n",
    "    n_repeat=10,\n",
    "    )\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ds[7806]\n",
    "plt.imshow(data[\"image\"].permute(1, 2, 0))\n",
    "plt.show()\n",
    "data[\"label\"], data[\"encoded_label\"], ds.le.inverse_transform(data[\"encoded_label\"].numpy().reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mossaic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fgvc.data.plant_clef_data import PlantMosaicDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/ubuntu/FGVC11/data/PlantClef/le.pkl\", \"rb\") as f:\n",
    "    le = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = PlantMosaicDataset(df=df, label_encoder=le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.learn_tag == \"train\"]), len(df[df.learn_tag == \"val\"]), len(df[df.learn_tag == \"val\"]), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ds[0]\n",
    "plt.imshow(data['image'].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"encoded_label\"], sum(data[\"encoded_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"species\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/ubuntu/FGVC11/data/PlantClef/PlantCLEF2024singleplanttrainingdata.csv\",  delimiter=\";\", escapechar=\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"path\"] = \"/home/ubuntu/FGVC11/data/PlantClef/images_train/images_max_side_800/\" + df.species_id.astype(str) + \"/\" + df.image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"path\"] = \"/home/ubuntu/FGVC11/data/PlantClef/images_train/PlantCLEF2024/\" + df.learn_tag + \"/\" + df.species_id.astype(str) + \"/\" + df.image_name\n",
    "# df.to_csv(\"/home/ubuntu/FGVC11/data/PlantClef/PlantCLEFTrainHQ.csv\", sep=';', index=False, quoting=csv.QUOTE_NONE, escapechar='/')\n",
    "\n",
    "# df[\"path\"] = \"/home/ubuntu/FGVC11/data/PlantClef/images_train/images_max_side_800/\" + df.species_id.astype(str) + \"/\" + df.image_name\n",
    "# df.to_csv(\"/home/ubuntu/FGVC11/data/PlantClef/PlantCLEFTrainLQ.csv\", sep=';', index=False, quoting=csv.QUOTE_NONE, escapechar='/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a one hot encoder\n",
    "y = df['species_id'].values.reshape(-1, 1)\n",
    "le = OneHotEncoder()\n",
    "y_trf = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the encoder\n",
    "i = 10\n",
    "print(y_trf[i].toarray())\n",
    "print(y[i], le.inverse_transform(y_trf[i].toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the decoder\n",
    "with open(\"/home/ubuntu/FGVC11/data/PlantClef/le.pkl\", \"wb\") as f: \n",
    "    pickle.dump(le, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['species_id'].values\n",
    "# load and check teh decoder\n",
    "with open(\"/home/ubuntu/FGVC11/data/PlantClef/le.pkl\", \"rb\") as f: \n",
    "    le = pickle.load(f)\n",
    "i = 10000\n",
    "y_trf = le.transform(y.reshape(-1, 1))\n",
    "print(y[i], le.inverse_transform(y_trf[i].toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "64*4*169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = omegaconf.OmegaConf.load(\"/home/ubuntu/FGVC11/configs/data/plant_clef_data.yaml\")\n",
    "datamodule = hydra.utils.instantiate(cfg)\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(datamodule.data_train), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(datamodule.data_train)//256 * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in datamodule.train_dataloader():\n",
    "    # print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(batch[\"image\"][0].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(batch[\"encoded_label\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and check the decoder\n",
    "with open(\"/home/ubuntu/FGVC11/data/PlantClef/le.pkl\", \"rb\") as f: \n",
    "    le = pickle.load(f)\n",
    "i = 10\n",
    "print(batch[\"label\"][i], le.inverse_transform(batch[\"encoded_label\"])[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = omegaconf.OmegaConf.load(\"/home/ubuntu/FGVC11/configs/model/plant_clef_model.yaml\")\n",
    "model = hydra.utils.instantiate(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_from_checkpoint(\"/home/ubuntu/FGVC11/logs/train/runs/test_edgenext_small_cross_entropy_specie_based_dataset_10/checkpoints/epoch_198.ckpt\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(columns=[\"path\", \"plot_id\", \"species_ids\"])\n",
    "submission_df[\"path\"] = glob(\"/home/ubuntu/FGVC11/data/PlantClef/images/*.jpg\")\n",
    "submission_df[\"plot_id\"] = submission_df[\"path\"].apply(lambda x: x.split(\"/\")[-1].split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = PlantCLEFDataset(\n",
    "    df=submission_df,\n",
    "    transform=datamodule.test_transform,\n",
    "    label_encoder=datamodule.le,\n",
    "    return_image=True,\n",
    "    return_labels=False,\n",
    "    return_metadata=False, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_ds[0][\"image\"].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = torch.utils.data.DataLoader(\n",
    "    dataset=test_ds,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cuda\");\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in tqdm(datamodule.test_dataloader()):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"encoded_label\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = datamodule.le.categories_[0]\n",
    "test_targets = []\n",
    "test_preds = []\n",
    "for batch in tqdm(datamodule.test_dataloader()):\n",
    "    image = batch[\"image\"].to(\"cuda\")\n",
    "    test_targets.append(batch[\"encoded_label\"].cpu().numpy())\n",
    "    with torch.no_grad():\n",
    "        output = torch.sigmoid(model(image))\n",
    "    test_preds.append(output.cpu().numpy())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_targets = np.concatenate(test_targets, axis=0)\n",
    "# test_preds = np.concatenate(test_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_preds.shape, test_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1_score(test_targets, test_preds > 0.5, average=\"samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1_score(test_targets, test_preds, average=\"samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresh = []\n",
    "# f1 = []\n",
    "# for i in range(test_targets.shape[0]):\n",
    "#     tgt = test_targets[:, i]\n",
    "#     prd = test_preds[:, i]\n",
    "    \n",
    "    # get the best threshold between 0 and 1 based on the f1 score\n",
    "    # f1 = []\n",
    "    # for t in np.linspace(0, 1, 11):\n",
    "    #     f1.append(f1_score(tgt, prd > t))\n",
    "    # # print(np.linspace(0, 1, 10)[np.argmax(f1)], f1[np.argmax(f1)])\n",
    "    # thresh.append(np.linspace(0, 1, 10)[np.argmax(f1)])\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresh = [i if i > 0.6 else 0.6 for i in thresh]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresh = np.array(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = datamodule.le.categories_[0]\n",
    "test_labels = []\n",
    "thresh = 0.65\n",
    "k = 20\n",
    "for batch in tqdm(test_dl):\n",
    "    image = batch[\"image\"].to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        output = torch.sigmoid(model(image))\n",
    "    raw_pred = output.cpu().numpy()\n",
    "    # break\n",
    "    raw_pred[raw_pred < thresh] = 0\n",
    "    for obj in raw_pred:\n",
    "        top_k_indices = np.argsort(obj)[-k:]\n",
    "        non_zero_indices = np.where(obj[top_k_indices] > 0)[0]\n",
    "        top_k_indices = top_k_indices[non_zero_indices]\n",
    "        test_labels.append(str(list(cats[top_k_indices].astype(object))))\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df[\"species_ids\"] = test_labels\n",
    "submission_df[[\"plot_id\", \"species_ids\"]].to_csv(\"my_run.csv\", sep=';', index=False, quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([[0, 1, 0, 1],[1, 0, 0, 0]]).float()\n",
    "y_ = torch.tensor([[0.1, 0.9, 0.9, 0.1], [0.1, 0.9, 0.9, 0.1]]).float()\n",
    "y.shape, y_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(y, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_positive_regularizer(preds, expected_num_pos, norm='2'):\n",
    "    # Assumes predictions in [0,1].\n",
    "    if norm == '1':\n",
    "        reg = torch.abs(preds.sum(1).mean(0) - expected_num_pos)\n",
    "    elif norm == '2':\n",
    "        reg = (preds.sum(1).mean(0) - expected_num_pos)**2\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_positive_regularizer(y_, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = SmoothBCELoss(num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.forward(y_, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import MultilabelF1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_per_sample = MultilabelF1Score(num_labels=4, threshold=0.5, average=\"macro\", multidim_average=\"samplewise\")\n",
    "macro_per_class = MultilabelF1Score(num_labels=4, threshold=0.5, average=\"macro\", multidim_average=\"global\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_per_sample = MultilabelF1Score(num_labels=4, threshold=0.5, average=\"micro\", multidim_average=\"samplewise\")\n",
    "micro_per_class = MultilabelF1Score(num_labels=4, threshold=0.5, average=\"micro\", multidim_average=\"global\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MultilabelF1Score(num_labels=4, threshold=0.5, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m(y_, y),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_per_class(y_, y),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_per_sample(y_, y),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
