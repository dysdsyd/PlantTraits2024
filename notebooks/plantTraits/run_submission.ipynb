{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "import hydra\n",
    "import lightning as pl\n",
    "from omegaconf import DictConfig\n",
    "from lightning import Callback, LightningDataModule, LightningModule, Trainer\n",
    "from lightning.pytorch.loggers import Logger\n",
    "\n",
    "from terralearn import utils\n",
    "\n",
    "import torch\n",
    "import hydra\n",
    "import omegaconf\n",
    "import pyrootutils\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle\n",
    "import timm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trait_columns = [\n",
    "    \"X4_mean\",\n",
    "    \"X11_mean\",\n",
    "    \"X18_mean\",\n",
    "    \"X50_mean\",\n",
    "    \"X26_mean\",\n",
    "    \"X3112_mean\",\n",
    "]\n",
    "sub_cols = [i.replace(\"_mean\", \"\") for i in trait_columns]\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from torchmetrics.regression import R2Score\n",
    "from fgvc.models.plant_traits_model import *\n",
    "from torchmetrics.functional import r2_score\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names = [\n",
    "    (\"v0_reg.csv\", 1),\n",
    "    (\"v0_1_reg.csv\", 1),\n",
    "    (\"v1_reg.csv\", 1),\n",
    "    (\"v1_clf.csv\", 1),\n",
    "    # (\"v1_1_reg.csv\", 2),\n",
    "    # (\"v1_1_clf.csv\", 2),\n",
    "    # (\"v1_2_reg.csv\", 2),\n",
    "    # (\"v1_2_clf.csv\", 2),\n",
    "    # (\"v1_3_reg.csv\", 1),\n",
    "    # (\"v1_3_clf.csv\", 1),\n",
    "    # (\"v1_3_bld.csv\", 1),\n",
    "    # (\"v1_4_reg.csv\", 1),\n",
    "    # (\"v1_4_clf.csv\", 1),\n",
    "    # (\"v1_4_bld.csv\", 1),\n",
    "    # (\"v1_5_reg.csv\", 1),\n",
    "    # (\"v1_5_clf.csv\", 1),\n",
    "    # (\"v1_5_bld.csv\", 1),\n",
    "    ]\n",
    "\n",
    "# load the csvs and take weighted average of the predictions for the sub_cols columns and out put final csv\n",
    "out = pd.DataFrame()\n",
    "weight_sum = 0\n",
    "for filename, weight in df_names:\n",
    "    df = pd.read_csv(filename)\n",
    "    if len(out) != 0:\n",
    "        out += df[sub_cols] * weight\n",
    "    else:\n",
    "        out = df[sub_cols] * weight\n",
    "    weight_sum += weight\n",
    "\n",
    "out = out / weight_sum\n",
    "df_avg = pd.DataFrame()\n",
    "df_avg[\"id\"] = df[\"id\"]\n",
    "df_avg[sub_cols] = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg.to_csv(\"avg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c planttraits2024 -f avg.csv -m \" avg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(glob(\"v*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.read_csv(\"v0_reg.csv\")\n",
    "# df2 = pd.read_csv(\"v0_1_reg.csv\")\n",
    "df3 = pd.read_csv(\"v1_1_reg.csv\")\n",
    "df4 = pd.read_csv(\"v1_1_clf.csv\")\n",
    "df5 = pd.read_csv(\"v1_2_reg.csv\")\n",
    "df6 = pd.read_csv(\"v1_2_clf.csv\")\n",
    "df3[sub_cols] = df3[sub_cols] + df4[sub_cols] + df5[sub_cols] + df6[sub_cols]\n",
    "df3[sub_cols] = df3[sub_cols] / 4\n",
    "df3.to_csv(\"avg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c planttraits2024 -f avg.csv -m \" mean v1_1 v1_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df[0]\n",
    "for df_each in df[1:]:\n",
    "    # sum the trait columns\n",
    "    df_out[sub_cols] += df_each[sub_cols]\n",
    "# take average\n",
    "df_out[sub_cols] /= len(df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.to_csv(\"avg_v0_v_1_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c planttraits2024 -f v_1_2_avg.csv -m \"v_1_2_avg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('avg_5_best.csv')\n",
    "print(r2_score(torch.tensor(sub[sub.columns[1:]].values), torch.tensor(df_out[sub.columns[1:]].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"v1_2_reg.csv\")\n",
    "df2 = pd.read_csv(\"v1_2_clf.csv\")\n",
    "df1[sub_cols] = df1[sub_cols] + df2[sub_cols] \n",
    "df1[sub_cols] = df1[sub_cols] / 2\n",
    "df1.to_csv(\"v_1_2_avg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, a * b, a+a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = omegaconf.OmegaConf.load(\"/home/ubuntu/FGVC11/configs/data/plant_traits_data.yaml\")\n",
    "cfg.batch_size = 128\n",
    "datamodule: LightningDataModule = hydra.utils.instantiate(cfg)\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = datamodule.data_train[11903]\n",
    "# plt.imshow(data[\"image\"].permute(1, 2, 0))\n",
    "# plt.show()\n",
    "# print(data[\"label\"])\n",
    "# print(data[\"original_label\"])\n",
    "# print(data[\"aux_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (len(datamodule.data_train)//(64*4))*30\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = omegaconf.OmegaConf.load(\"/home/ubuntu/FGVC11/configs/model/plant_traits_model.yaml\")\n",
    "model = hydra.utils.instantiate(cfg)\n",
    "\n",
    "\n",
    "\n",
    "model = model.load_from_checkpoint(\"/home/ubuntu/FGVC11/logs/train/runs/blk_4_blended_traits_simple_mixup/checkpoints/epoch_101.ckpt\");\n",
    "model = model.train();\n",
    "model = model.eval();\n",
    "model = model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ??model.model.body.forward_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/home/ubuntu/FGVC11/data/PlantTrait/test.csv')\n",
    "df_test['path'] = '/home/ubuntu/FGVC11/data/PlantTrait/test_images/' + df_test['id'].astype(str) + '.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reg_weight, model.clf_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_pred = []\n",
    "clf_pred = []\n",
    "bld_pred = []\n",
    "i = 0\n",
    "for batch in tqdm(datamodule.test_dataloader()):\n",
    "    # Unpack the batch\n",
    "    x, x_ = batch[\"image\"].to(device), batch[\"metadata\"].to(device)\n",
    "    # Move data to the device\n",
    "\n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        pred_enc, specie_logits = model.model.forward_alt(x, x_)\n",
    "        pred = model.model.le.inverse_transform(pred_enc.clone().detach())\n",
    "\n",
    "        pred_specie = torch.argmax(specie_logits, dim=1)\n",
    "        pred_specie_traits = model.specie_traits[pred_specie]\n",
    "        # Append predictions to the list\n",
    "        reg_pred.append(pred.cpu())\n",
    "        clf_pred.append(pred_specie_traits.cpu())\n",
    "\n",
    "        if model.blend_traits:\n",
    "            blended_traits = (\n",
    "                model.reg_weight * pred + model.clf_weight * pred_specie_traits\n",
    "            ) / (model.reg_weight + model.clf_weight)\n",
    "            # pred_clf_enc = model.model.le.transform(pred_specie_traits)\n",
    "            # blended_traits_enc = model.trait_blender([pred_enc, pred_clf_enc])\n",
    "            # blended_traits = model.model.le.inverse_transform(blended_traits_enc)\n",
    "            bld_pred.append(blended_traits.cpu())\n",
    "\n",
    "# Concatenate predictions from all batches\n",
    "reg_pred = torch.concat(reg_pred, dim=0)\n",
    "clf_pred = torch.concat(clf_pred, dim=0)\n",
    "if model.blend_traits:\n",
    "    bld_pred = torch.concat(bld_pred, dim=0)\n",
    "# all_tgts = torch.concat(all_tgts, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_pred = reg_pred.numpy()\n",
    "clf_pred = clf_pred.numpy()\n",
    "if model.blend_traits:\n",
    "    bld_pred = bld_pred.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the predictions and corresponding IDs\n",
    "reg_df = pd.DataFrame({\n",
    "    'id': df_test['id'].values,\n",
    "    'X4': reg_pred[:, 0],\n",
    "    'X11': reg_pred[:, 1],\n",
    "    'X18': reg_pred[:, 2],\n",
    "    'X50': reg_pred[:, 3],\n",
    "    'X26': reg_pred[:, 4],\n",
    "    'X3112': reg_pred[:, 5],\n",
    "})\n",
    "# Create a DataFrame with the predictions and corresponding IDs\n",
    "clf_df = pd.DataFrame({\n",
    "    'id': df_test['id'].values,\n",
    "    'X4': clf_pred[:, 0],\n",
    "    'X11': clf_pred[:, 1],\n",
    "    'X18': clf_pred[:, 2],\n",
    "    'X50': clf_pred[:, 3],\n",
    "    'X26': clf_pred[:, 4],\n",
    "    'X3112': clf_pred[:, 5],\n",
    "})\n",
    "if model.blend_traits:\n",
    "    bld_df = pd.DataFrame({\n",
    "        'id': df_test['id'].values,\n",
    "        'X4': bld_pred[:, 0],\n",
    "        'X11': bld_pred[:, 1],\n",
    "        'X18': bld_pred[:, 2],\n",
    "        'X50': bld_pred[:, 3],\n",
    "        'X26': bld_pred[:, 4],\n",
    "        'X3112': bld_pred[:, 5],\n",
    "    })\n",
    "# submission_df.to_csv('submission.csv', index=False)\n",
    "sub = pd.read_csv('avg_5_best.csv')\n",
    "print(r2_score(torch.tensor(sub[sub.columns[1:]].values), torch.tensor(reg_df[sub.columns[1:]].values)))\n",
    "print(r2_score(torch.tensor(sub[sub.columns[1:]].values), torch.tensor(clf_df[sub.columns[1:]].values)))\n",
    "if model.blend_traits:\n",
    "    print(r2_score(torch.tensor(sub[sub.columns[1:]].values), torch.tensor(bld_df[sub.columns[1:]].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comb_df = (reg_df + clf_df)/2\n",
    "# comb_df['id'] = reg_df['id']\n",
    "# print(r2_score(torch.tensor(sub[sub.columns[1:]].values), torch.tensor(comb_df[sub.columns[1:]].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df.to_csv('v1_5_reg.csv', index=False)\n",
    "clf_df.to_csv('v1_5_clf.csv', index=False)\n",
    "if model.blend_traits:\n",
    "    bld_df.to_csv('v1_5_bld.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bld_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best = pd.read_csv('best.csv')\n",
    "# edit = best.copy()\n",
    "# for i in range(len(best)):\n",
    "#     a = best.iloc[i].values[1:]\n",
    "#     b = clf_df.iloc[i].values[1:]\n",
    "#     score = r2_score(torch.tensor(a), torch.tensor(b))\n",
    "#     if score > 0.7:\n",
    "#         edit.iloc[i, 1:] = clf_df.iloc[i].values[1:]\n",
    "# edit.to_csv('edit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c planttraits2024 -f v1_5_bld.csv -m \"v1_5_bld\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c planttraits2024 -f v1_5_reg.csv -m \"v1_5_reg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c planttraits2024 -f v1_5_clf.csv -m \"v1_5_clf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference on all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fgvc.data.plant_traits_data import PlantTraitsDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete = pd.read_csv(\"/home/ubuntu/FGVC11/data/PlantTrait/df_complete.csv\")\n",
    "df_complete = df_complete[df_complete.split == \"train\"]\n",
    "plant_dataset = PlantTraitsDataset(\n",
    "                df=df_complete,\n",
    "                transform=datamodule.test_transform,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_loader = DataLoader(plant_dataset, batch_size=128, num_workers=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = []\n",
    "i = 0\n",
    "for batch in tqdm(plant_loader):\n",
    "    # Unpack the batch\n",
    "    x, x_ = batch[\"image\"].to(device), batch[\"metadata\"].to(device)\n",
    "    # Move data to the device\n",
    "\n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        pred_enc = model.model.forward_alt(x, x_)\n",
    "        pred = model.model.le.inverse_transform(pred_enc.clone().detach())\n",
    "        pred = pred.cpu()\n",
    "    # Append predictions to the list\n",
    "    all_predictions.append(pred)\n",
    "# Concatenate predictions from all batches\n",
    "all_predictions = torch.concat(all_predictions, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = all_predictions.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trait_columns_pred = [i+\"_pred\" for i in trait_columns]\n",
    "trait_columns_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete[trait_columns_pred] = all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete[df_complete.split == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete.to_csv(\"/home/ubuntu/FGVC11/data/PlantTrait/df_complete.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping to the closest values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv('/home/ubuntu/FGVC11/data/PlantTrait/df_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_traits = full_df[trait_columns + ['species']][full_df.split != 'test'].groupby('species').mean()\n",
    "species_traits.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv(\"avg_v0_v_1_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_traits = []\n",
    "for _, row in tqdm(submission_df.iterrows(), total=len(submission_df)):\n",
    "    obj_traits = []\n",
    "    for col in trait_columns:\n",
    "        col_sub = col.replace(\"_mean\", \"\")\n",
    "        pred_trt = row[col_sub]\n",
    "        tgt_trts = species_traits[col]\n",
    "        mapped_trait = tgt_trts[np.argmin(abs(pred_trt - tgt_trts))]\n",
    "        obj_traits.append(mapped_trait)\n",
    "        # break\n",
    "    obj_traits = np.array(obj_traits)\n",
    "    mapped_traits.append(obj_traits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_traits = np.array(mapped_traits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the predictions and corresponding IDs\n",
    "mapped_sub = pd.DataFrame({\n",
    "    'id': submission_df['id'].values,\n",
    "    'X4': mapped_traits[:, 0],\n",
    "    'X11': mapped_traits[:, 1],\n",
    "    'X18': mapped_traits[:, 2],\n",
    "    'X50': mapped_traits[:, 3],\n",
    "    'X26': mapped_traits[:, 4],\n",
    "    'X3112': mapped_traits[:, 5],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in trait_columns:\n",
    "#     col = col.replace(\"_mean\", \"\")\n",
    "#     print(f\"r2 {col}: {r2_score(sub[col], mapped_sub[col])}\")\n",
    "best_submission = pd.read_csv(\"avg_v0_v_1_2.csv\")\n",
    "r2_score(torch.tensor(best_submission[best_submission.columns[1:]].values), torch.tensor(mapped_sub[best_submission.columns[1:]].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_sub.to_csv('mapped_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c planttraits2024 -f mapped_sub.csv -m \"mapped_v0_v1_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from fgvc.models.plant_traits_model import StructuredSelfAttention\n",
    "\n",
    "class TraitBlender(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_blocks=1, n_models=2, dropout_rate=0.1):\n",
    "        super(TraitBlender, self).__init__()\n",
    "        self.n_models = n_models\n",
    "        # Adjust the input dimension based on the number of models (traits sets)\n",
    "        self.self_attention = StructuredSelfAttention(input_dim * n_models, output_dim, num_blocks)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.final_layer = nn.Linear(output_dim, input_dim)  # Output dimension aligns back to the number of traits\n",
    "\n",
    "    def forward(self, traits_list):\n",
    "        # Ensure we have the correct number of trait sets\n",
    "        if len(traits_list) != self.n_models:\n",
    "            raise ValueError(f\"Expected {self.n_models} sets of traits, but got {len(traits_list)}\")\n",
    "\n",
    "        # Concatenate the input traits along the feature dimension\n",
    "        combined_input = torch.cat(traits_list, dim=1)\n",
    "\n",
    "        # Process combined input through the Structured Self-Attention\n",
    "        attention_output = self.self_attention(combined_input)\n",
    "\n",
    "        # Apply dropout and pass through the final linear layer\n",
    "        dropped_output = self.dropout(attention_output)\n",
    "        blended_traits = self.final_layer(dropped_output)\n",
    "\n",
    "        return blended_traits\n",
    "\n",
    "# Assuming the StructuredSelfAttention class is defined as previously\n",
    "# Example usage:\n",
    "n_models = 3  # Number of sets of traits to blend\n",
    "num_features = 6  # Number of features per trait\n",
    "\n",
    "trait_blender = TraitBlender(num_features, num_features * n_models, num_blocks=1, n_models=n_models, dropout_rate=0.1)\n",
    "\n",
    "# Example tensors for multiple sets of pred_traits\n",
    "pred_traits_1 = torch.rand(10, 6)\n",
    "pred_traits_2 = torch.rand(10, 6)\n",
    "pred_traits_3 = torch.rand(10, 6)\n",
    "\n",
    "# Get the blended traits\n",
    "blended_traits = trait_blender([pred_traits_1, pred_traits_2, pred_traits_3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_traits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
