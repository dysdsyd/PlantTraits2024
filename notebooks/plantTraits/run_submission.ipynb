{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "import hydra\n",
    "import lightning as pl\n",
    "from omegaconf import DictConfig\n",
    "from lightning import Callback, LightningDataModule, LightningModule, Trainer\n",
    "from lightning.pytorch.loggers import Logger\n",
    "\n",
    "import torch\n",
    "import hydra\n",
    "import omegaconf\n",
    "import pyrootutils\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle\n",
    "import timm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trait_columns = [\n",
    "    \"X4_mean\",\n",
    "    \"X11_mean\",\n",
    "    \"X18_mean\",\n",
    "    \"X50_mean\",\n",
    "    \"X26_mean\",\n",
    "    \"X3112_mean\",\n",
    "]\n",
    "sub_cols = [i.replace(\"_mean\", \"\") for i in trait_columns]\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from torchmetrics.regression import R2Score\n",
    "from fgvc.models.plant_traits_model import *\n",
    "from torchmetrics.functional import r2_score\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "# setup the datamodule\n",
    "cfg = omegaconf.OmegaConf.load(\"/home/ubuntu/FGVC11/configs/data/plant_traits_data.yaml\")\n",
    "cfg.batch_size = 128\n",
    "datamodule: LightningDataModule = hydra.utils.instantiate(cfg)\n",
    "datamodule.setup()\n",
    "\n",
    "# setup the model\n",
    "cfg = omegaconf.OmegaConf.load(\"/home/ubuntu/FGVC11/configs/model/plant_traits_model.yaml\")\n",
    "cfg.reg_traits = True\n",
    "cfg.clf_traits = True\n",
    "cfg.bld_traits = True\n",
    "cfg.soft_clf_traits = True\n",
    "cfg.model.body = \"vitl\"\n",
    "model = hydra.utils.instantiate(cfg)\n",
    "# load the checkpoint\n",
    "model = model.load_from_checkpoint(\"/path/to/ckpt\", map_location=device);\n",
    "model = model.train();\n",
    "model = model.eval();\n",
    "model = model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/home/ubuntu/FGVC11/data/PlantTrait/test.csv')\n",
    "df_test['path'] = '/home/ubuntu/FGVC11/data/PlantTrait/test_images/' + df_test['id'].astype(str) + '.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_pred = []\n",
    "clf_pred = []\n",
    "clf_soft_pred = []\n",
    "bld_pred = []\n",
    "i = 0\n",
    "for batch in tqdm(datamodule.test_dataloader()):\n",
    "    # Unpack the batch\n",
    "    x, x_ = batch[\"image\"].to(device), batch[\"metadata\"].to(device)\n",
    "    # Move data to the device\n",
    "\n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        pred_enc, specie_logits = model.model.forward_alt(x, x_)\n",
    "        \n",
    "        if model.reg_traits:\n",
    "            assert not torch.isnan(pred_enc).any()\n",
    "            # raw predicted label\n",
    "            pred = model.model.le.inverse_transform(pred_enc.clone().detach())\n",
    "            bld_traits = torch.zeros_like(pred)\n",
    "            reg_pred.append(pred.cpu())\n",
    "        \n",
    "        if model.clf_traits:\n",
    "            pred_specie = torch.argmax(specie_logits, dim=1)\n",
    "            pred_specie_traits = model.specie_traits[pred_specie]\n",
    "            bld_traits = torch.zeros_like(pred_specie_traits)\n",
    "            clf_pred.append(pred_specie_traits.cpu())\n",
    "        \n",
    "        if model.soft_clf_traits:\n",
    "            specie_probs = F.softmax(specie_logits, dim=1)\n",
    "            pred_specie_traits_soft = torch.matmul(\n",
    "                specie_probs,\n",
    "                model.specie_traits\n",
    "                )\n",
    "            bld_traits = torch.zeros_like(pred_specie_traits_soft)\n",
    "            clf_soft_pred.append(pred_specie_traits_soft.cpu())\n",
    "            \n",
    "        if model.bld_traits:\n",
    "            assert (\n",
    "                sum([model.reg_traits, model.clf_traits, model.soft_clf_traits]) > 1\n",
    "            ), \"At least two heads should be active to blend traits\"\n",
    "            # bld_traits = torch.zeros_like(dummy_traits)\n",
    "            denominator = torch.zeros_like(model.dummy_weights)\n",
    "            if model.reg_traits:\n",
    "                bld_traits += model.reg_weight * pred\n",
    "                denominator += model.reg_weight\n",
    "            if model.clf_traits:\n",
    "                bld_traits += model.clf_weight * pred_specie_traits\n",
    "                denominator += model.clf_weight\n",
    "            if model.soft_clf_traits:\n",
    "                bld_traits += model.soft_clf_weight * pred_specie_traits_soft\n",
    "                denominator += model.soft_clf_weight\n",
    "            bld_traits = bld_traits / denominator\n",
    "            bld_pred.append(bld_traits.cpu())\n",
    "\n",
    "# Concatenate predictions from all batches\n",
    "if model.reg_traits:\n",
    "    reg_pred = torch.concat(reg_pred, dim=0).numpy()\n",
    "if model.clf_traits:\n",
    "    clf_pred = torch.concat(clf_pred, dim=0).numpy()\n",
    "if model.soft_clf_traits:\n",
    "    clf_soft_pred = torch.concat(clf_soft_pred, dim=0).numpy()\n",
    "if model.bld_traits:\n",
    "    bld_pred = torch.concat(bld_pred, dim=0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission dfs sanity check submission with the best submission so far\n",
    "if model.reg_traits:\n",
    "    reg_df = pd.DataFrame({\n",
    "        'id': df_test['id'].values,\n",
    "        'X4': reg_pred[:, 0],\n",
    "        'X11': reg_pred[:, 1],\n",
    "        'X18': reg_pred[:, 2],\n",
    "        'X50': reg_pred[:, 3],\n",
    "        'X26': reg_pred[:, 4],\n",
    "        'X3112': reg_pred[:, 5],\n",
    "    })\n",
    "if model.clf_traits:\n",
    "    clf_df = pd.DataFrame({\n",
    "        'id': df_test['id'].values,\n",
    "        'X4': clf_pred[:, 0],\n",
    "        'X11': clf_pred[:, 1],\n",
    "        'X18': clf_pred[:, 2],\n",
    "        'X50': clf_pred[:, 3],\n",
    "        'X26': clf_pred[:, 4],\n",
    "        'X3112': clf_pred[:, 5],\n",
    "    })\n",
    "if model.soft_clf_traits:\n",
    "    clf_soft_df = pd.DataFrame({\n",
    "        'id': df_test['id'].values,\n",
    "        'X4': clf_soft_pred[:, 0],\n",
    "        'X11': clf_soft_pred[:, 1],\n",
    "        'X18': clf_soft_pred[:, 2],\n",
    "        'X50': clf_soft_pred[:, 3],\n",
    "        'X26': clf_soft_pred[:, 4],\n",
    "        'X3112': clf_soft_pred[:, 5],\n",
    "    })\n",
    "if model.bld_traits:\n",
    "    bld_df = pd.DataFrame({\n",
    "        'id': df_test['id'].values,\n",
    "        'X4': bld_pred[:, 0],\n",
    "        'X11': bld_pred[:, 1],\n",
    "        'X18': bld_pred[:, 2],\n",
    "        'X50': bld_pred[:, 3],\n",
    "        'X26': bld_pred[:, 4],\n",
    "        'X3112': bld_pred[:, 5],\n",
    "    })\n",
    "sub = pd.read_csv('avg.csv')\n",
    "if model.reg_traits:\n",
    "    print(r2_score(torch.tensor(sub[sub.columns[1:]].values), torch.tensor(reg_df[sub.columns[1:]].values)))\n",
    "if model.clf_traits:\n",
    "    print(r2_score(torch.tensor(sub[sub.columns[1:]].values), torch.tensor(clf_df[sub.columns[1:]].values)))\n",
    "if model.soft_clf_traits:\n",
    "    print(r2_score(torch.tensor(sub[sub.columns[1:]].values), torch.tensor(clf_soft_df[sub.columns[1:]].values)))\n",
    "if model.bld_traits:\n",
    "    print(r2_score(torch.tensor(sub[sub.columns[1:]].values), torch.tensor(bld_df[sub.columns[1:]].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the submission\n",
    "m_name = \"experiment name\"\n",
    "if model.reg_traits:\n",
    "    reg_df.to_csv(f'{m_name}_reg.csv', index=False)\n",
    "if model.clf_traits:\n",
    "    clf_df.to_csv(f'{m_name}_clf.csv', index=False)\n",
    "if model.soft_clf_traits:\n",
    "    clf_soft_df.to_csv(f'{m_name}_clf_soft.csv', index=False)\n",
    "if model.bld_traits:\n",
    "    bld_df.to_csv(f'{m_name}_bld.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c planttraits2024 -f sub.csv -m \"sub\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names = [\n",
    "   (\"v2_4_reg.csv\", 1),\n",
    "    (\"v2_4_clf.csv\", 1),\n",
    "    (\"v2_4_4_reg.csv\", 1),\n",
    "    (\"v2_4_4_clf.csv\", 1),\n",
    "    (\"v2_1_2_reg.csv\", 1),\n",
    "    (\"v2_1_2_clf.csv\", 1),\n",
    "    (\"v2_1_3_reg.csv\", 1),\n",
    "    (\"v2_1_3_clf.csv\", 1),\n",
    "    (\"v4_all_v2_all_data_clf_soft.csv\", 5),\n",
    "    (\"v4_all_v2_vitl_all_data_clf_soft.csv\", 7),\n",
    "    (\"v5_vitb_clf_soft.csv\", 7),\n",
    "    (\"v5_vitl_clf_soft.csv\", 9),\n",
    "    (\"v5_vitb_alldata_clf_soft.csv\", 9),\n",
    "    (\"v5_vitb_alldata_clf_soft.csv\", 9),\n",
    "    (\"v5_vitl_alldata_clf_soft.csv\", 11),\n",
    "    (\"v5_vitl_alldata_6blk_clf_soft.csv\", 11),\n",
    "    (\"v6_vitl_alldata_8blk_clf_soft.csv\", 13),\n",
    "    ]\n",
    "\n",
    "# load the csvs and take weighted average of the predictions for the sub_cols columns and out put final csv\n",
    "out = pd.DataFrame()\n",
    "weight_sum = 0\n",
    "for filename, weight in df_names:\n",
    "    df = pd.read_csv(filename)\n",
    "    if len(out) != 0:\n",
    "        out += df[sub_cols] * weight\n",
    "    else:\n",
    "        out = df[sub_cols] * weight\n",
    "    weight_sum += weight\n",
    "\n",
    "out = out / weight_sum\n",
    "df_avg = pd.DataFrame()\n",
    "df_avg[\"id\"] = df[\"id\"]\n",
    "df_avg[sub_cols] = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg.to_csv(\"avg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c planttraits2024 -f avg.csv -m \"avg\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
