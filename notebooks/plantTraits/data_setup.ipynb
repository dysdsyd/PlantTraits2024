{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import omegaconf\n",
    "import hydra\n",
    "from lightning import Callback, LightningDataModule, LightningModule, Trainer\n",
    "from omegaconf import DictConfig\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from fgvc.data.plant_traits_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all columns must be identical to be consider the same species\n",
    "trait_columns = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']\n",
    "aux_columns = list(\n",
    "            map(lambda x: x.replace(\"mean\", \"sd\"), trait_columns)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X4_mean</th>\n",
       "      <th>X11_mean</th>\n",
       "      <th>X18_mean</th>\n",
       "      <th>X50_mean</th>\n",
       "      <th>X26_mean</th>\n",
       "      <th>X3112_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>55554.000000</td>\n",
       "      <td>55554.000000</td>\n",
       "      <td>55554.000000</td>\n",
       "      <td>55554.000000</td>\n",
       "      <td>55554.000000</td>\n",
       "      <td>55554.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.452789</td>\n",
       "      <td>13.907804</td>\n",
       "      <td>2.252462</td>\n",
       "      <td>1.393314</td>\n",
       "      <td>16.969752</td>\n",
       "      <td>1300.792687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.209653</td>\n",
       "      <td>8.189753</td>\n",
       "      <td>4.049120</td>\n",
       "      <td>0.748973</td>\n",
       "      <td>49.908438</td>\n",
       "      <td>1951.040578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.368824</td>\n",
       "      <td>8.590398</td>\n",
       "      <td>0.201960</td>\n",
       "      <td>1.022802</td>\n",
       "      <td>0.202938</td>\n",
       "      <td>143.250464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.473778</td>\n",
       "      <td>14.343725</td>\n",
       "      <td>0.510616</td>\n",
       "      <td>1.393763</td>\n",
       "      <td>1.456990</td>\n",
       "      <td>519.442038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.598398</td>\n",
       "      <td>18.934532</td>\n",
       "      <td>2.013909</td>\n",
       "      <td>1.806646</td>\n",
       "      <td>8.489919</td>\n",
       "      <td>1605.332660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.856600</td>\n",
       "      <td>40.478892</td>\n",
       "      <td>23.294858</td>\n",
       "      <td>3.584879</td>\n",
       "      <td>492.559161</td>\n",
       "      <td>12978.600313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            X4_mean      X11_mean      X18_mean      X50_mean      X26_mean  \\\n",
       "count  55554.000000  55554.000000  55554.000000  55554.000000  55554.000000   \n",
       "mean       0.452789     13.907804      2.252462      1.393314     16.969752   \n",
       "std        0.209653      8.189753      4.049120      0.748973     49.908438   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.368824      8.590398      0.201960      1.022802      0.202938   \n",
       "50%        0.473778     14.343725      0.510616      1.393763      1.456990   \n",
       "75%        0.598398     18.934532      2.013909      1.806646      8.489919   \n",
       "max        0.856600     40.478892     23.294858      3.584879    492.559161   \n",
       "\n",
       "         X3112_mean  \n",
       "count  55554.000000  \n",
       "mean    1300.792687  \n",
       "std     1951.040578  \n",
       "min        0.000000  \n",
       "25%      143.250464  \n",
       "50%      519.442038  \n",
       "75%     1605.332660  \n",
       "max    12978.600313  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.read_csv('/home/ubuntu/FGVC11/data/PlantTrait/df_processed.csv')\n",
    "df_full[trait_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/home/ubuntu/FGVC11/data/PlantTrait/train.csv')\n",
    "df_train['path'] = '/home/ubuntu/FGVC11/data/PlantTrait/train_images/' + df_train['id'].astype(str) + '.jpeg'\n",
    "\n",
    "df_test = pd.read_csv('/home/ubuntu/FGVC11/data/PlantTrait/test.csv')\n",
    "df_test['path'] = '/home/ubuntu/FGVC11/data/PlantTrait/test_images/' + df_test['id'].astype(str) + '.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_cols = df_train.drop(\n",
    "                columns=[\"id\", \"path\"] + trait_columns + aux_columns\n",
    "            ).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[trait_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_columns = [i+\"_log\" for i in trait_columns]\n",
    "# df_train[log_columns] = np.log10(df_train[trait_columns])\n",
    "for col in trait_columns:\n",
    "    # lower quantile\n",
    "    lower_quantile = df_train[col].quantile(0.005)\n",
    "    upper_quantile = df_train[col].quantile(0.99)  \n",
    "    df_train = df_train[(df_train[col] < upper_quantile)]\n",
    "    df_train = df_train[(df_train[col] > lower_quantile)]\n",
    "    # df_train = df_train[(df_train[col] > 0)]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[trait_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[aux_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna(subset=log_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Val/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add species column\n",
    "df_train['species'] = df_train.groupby(trait_columns).ngroup()\n",
    "df_train['species'] = df_train['species'].astype(str)\n",
    "species_counts = df_train['species'].nunique()\n",
    "\n",
    "print (f\"{species_counts} unique species found in {len(df_train)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['species'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a split column and do train_testsplit based on species column\n",
    "df_train['split'] = 'train'\n",
    "# create a dictionary to store the indices of each species\n",
    "species_indices = {}\n",
    "\n",
    "# iterate over each species and select 20% of its indices for validation\n",
    "for species in tqdm(df_train['species'].unique()):\n",
    "    species_indices[species] = np.random.choice(df_train[df_train['species'] == species].index, \n",
    "                                                size=int(len(df_train[df_train['species'] == species]) * 0.3), \n",
    "                                                replace=False)\n",
    "\n",
    "# update the split column for the selected validation indices\n",
    "df_train.loc[np.concatenate(list(species_indices.values())), 'split'] = 'val'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['split'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"split\"] = \"test\"\n",
    "df_full = pd.concat([df_train, df_test], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NA in metadata columns\n",
    "df_full.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['split'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Metadata Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Shift each column in metadata_cols so all values are positive\n",
    "# for col in metadata_cols:\n",
    "#     min_value = df_full[col].min()\n",
    "#     if min_value < 0:\n",
    "#         df_full[col] += abs(min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "scale = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[metadata_cols] = scale.fit_transform(df_full[metadata_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[df_full.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.to_csv('/home/ubuntu/FGVC11/data/PlantTrait/df_processed_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in np.log10(df_full[trait_columns][df_full.split != \"test\"] + 1e-6).max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fgvc.models.plant_traits_model import LabelEncoder, MinMaxLabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[trait_columns][df_full.split != \"test\"].hist(bins=50, figsize=(10, 8))\n",
    "plt.show()\n",
    "X = torch.Tensor(df_full[trait_columns][df_full.split != \"test\"].values)\n",
    "t = le.transform(X)\n",
    "t = pd.DataFrame(t, columns=trait_columns)\n",
    "t.hist(bins=50, figsize=(10, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.columns[1:164]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv('/home/ubuntu/FGVC11/data/PlantTrait/df_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[trait_columns].descirb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_species_traits = df_full.groupby('species')[trait_columns].first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_species_traits.to_csv('/home/ubuntu/FGVC11/data/PlantTrait/species_traits.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specie_traits = torch.tensor(df_species_traits[trait_columns].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(specie_traits, '/home/ubuntu/FGVC11/data/PlantTrait/specie_traits.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specie_traits[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[\"species\"][df_full.split == \"val\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(df_full[\"species\"][df_full.split != \"test\"].unique()), max(df_full[\"species\"][df_full.split != \"test\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_full[\"species\"][df_full.split != \"test\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
