{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import omegaconf\n",
    "import hydra\n",
    "from lightning import Callback, LightningDataModule, LightningModule, Trainer\n",
    "from omegaconf import DictConfig\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from fgvc.data.plant_traits_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all columns must be identical to be consider the same species\n",
    "trait_columns = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']\n",
    "aux_columns = list(\n",
    "            map(lambda x: x.replace(\"mean\", \"sd\"), trait_columns)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/home/ubuntu/FGVC11/data/PlantTrait/train.csv')\n",
    "df_train['path'] = '/home/ubuntu/FGVC11/data/PlantTrait/train_images/' + df_train['id'].astype(str) + '.jpeg'\n",
    "\n",
    "df_test = pd.read_csv('/home/ubuntu/FGVC11/data/PlantTrait/test.csv')\n",
    "df_test['path'] = '/home/ubuntu/FGVC11/data/PlantTrait/test_images/' + df_test['id'].astype(str) + '.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_cols = df_train.drop(\n",
    "                columns=[\"id\", \"path\"] + trait_columns + aux_columns\n",
    "            ).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in trait_columns:\n",
    "    upper_quantile = df_train[col].quantile(0.98)  \n",
    "    df_train = df_train[(df_train[col] < upper_quantile)]\n",
    "    df_train = df_train[(df_train[col] > 0)]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Val/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add species column\n",
    "df_train['species'] = df_train.groupby(trait_columns).ngroup()\n",
    "df_train['species'] = df_train['species'].astype(str)\n",
    "species_counts = df_train['species'].nunique()\n",
    "\n",
    "print (f\"{species_counts} unique species found in {len(df_train)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['species'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a split column and do train_testsplit based on species column\n",
    "df_train['split'] = 'train'\n",
    "# create a dictionary to store the indices of each species\n",
    "species_indices = {}\n",
    "\n",
    "# iterate over each species and select 20% of its indices for validation\n",
    "for species in tqdm(df_train['species'].unique()):\n",
    "    species_indices[species] = np.random.choice(df_train[df_train['species'] == species].index, \n",
    "                                                size=int(len(df_train[df_train['species'] == species]) * 0.3), \n",
    "                                                replace=False)\n",
    "\n",
    "# update the split column for the selected validation indices\n",
    "df_train.loc[np.concatenate(list(species_indices.values())), 'split'] = 'val'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['split'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"split\"] = \"test\"\n",
    "df_full = pd.concat([df_train, df_test], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NA in metadata columns\n",
    "df_full.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Metadata Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[metadata_cols] = scale.fit_transform(df_full[metadata_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.to_csv('/home/ubuntu/FGVC11/data/PlantTrait/df_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fgvc.models.plant_traits_model import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[trait_columns].hist(bins=50, figsize=(10, 8))\n",
    "plt.show()\n",
    "X = torch.Tensor(df_train[trait_columns].values)\n",
    "t = le.transform(X)\n",
    "t = pd.DataFrame(t, columns=trait_columns)\n",
    "t.hist(bins=50, figsize=(10, 8))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
