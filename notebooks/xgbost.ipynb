{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "1. Join the kaggle contest - https://www.kaggle.com/competitions/planttraits2024\n",
    "2. Install kaggle cli - https://github.com/Kaggle/kaggle-api/blob/main/docs/README.md\n",
    "3. Download the data - `kaggle competitions download -c planttraits2024`\n",
    "4. Unzip the data\n",
    "5. Install FGVC repo - `pip install -e .` and `pip install -r requirement.txt` in the desired env\n",
    "5. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import omegaconf\n",
    "import hydra\n",
    "from lightning import Callback, LightningDataModule, LightningModule, Trainer\n",
    "from omegaconf import DictConfig\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup train metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/home/ubuntu/FGVC11/data/PlantTrait/df_train.csv')\n",
    "cfg = omegaconf.OmegaConf.load(\"/home/ubuntu/FGVC11/configs/data/plant_traits_data.yaml\")\n",
    "datamodule: LightningDataModule = hydra.utils.instantiate(cfg)\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = datamodule.data_train.class_names\n",
    "aux_col = datamodule.data_train.aux_class_names\n",
    "metadata_col = list(set(df_train.columns) - set(label_col) - set(aux_col) - set([\"path\", \"id\"]))\n",
    "len(label_col), len(aux_col), len(metadata_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the labels\n",
    "df_train = pd.read_csv('/home/ubuntu/FGVC11/data/PlantTrait/df_train.csv')\n",
    "print(df_train.shape)\n",
    "df_train = df_train.dropna(subset=(label_col + metadata_col))\n",
    "for column in label_col:\n",
    "    upper_quantile = df_train[column].quantile(0.98)  \n",
    "    df_train = df_train[(df_train[column] < upper_quantile)]\n",
    "    df_train = df_train[(df_train[column] > 0)]   \n",
    "    df_train[column] = np.log(df_train[column]) \n",
    "print(df_train.shape)\n",
    "df_train[label_col].hist(bins=50, figsize=(10, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the metadata\n",
    "original_means = {}\n",
    "original_stds = {}\n",
    "\n",
    "for column in metadata_col:\n",
    "    # Calculate the mean and standard deviation for each column\n",
    "    original_means[column] = df_train[column].mean()\n",
    "    original_stds[column] = df_train[column].std()\n",
    "\n",
    "    df_train[column] = (df_train[column] - original_means[column]) / original_stds[column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding CLIP feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = []\n",
    "for _, row in tqdm(df_train.iterrows(), total=len(df_train)):\n",
    "    image = preprocess(Image.open(row[\"path\"])).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image)\n",
    "        feats.append(image_features.view(-1).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = np.array(feats)\n",
    "np.save(\"feats.npy\", feats)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_test = pd.read_csv('/home/ubuntu/FGVC11/data/PlantTrait/df_test.csv')\n",
    "# for column in metadata_col:    \n",
    "#     df_test[column] = (df_test[column] - original_means[column]) / original_stds[column]\n",
    "\n",
    "for column in metadata_col:\n",
    "    # Calculate the mean and standard deviation for each column\n",
    "    mean = original_means[column] #df_test[column].mean()\n",
    "    std = original_stds[column] #df_test[column].std()\n",
    "    df_test[column] = (df_test[column] - mean) / std\n",
    "\n",
    "# add clip features for test data\n",
    "test_feats = []\n",
    "for _, row in tqdm(df_test.iterrows(), total=len(df_test)):\n",
    "    image = preprocess(Image.open(row[\"path\"])).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image)\n",
    "        test_feats.append(image_features.view(-1).cpu().numpy())\n",
    "\n",
    "# save test feats\n",
    "test_feats = np.array(test_feats)\n",
    "np.save(\"test_feats.npy\", test_feats)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the training data\n",
    "X = np.concatenate([df_train[metadata_col].values, feats], axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add clip feaures and save the final test data\n",
    "x_final = np.concatenate([df_test[metadata_col].values, test_feats], axis=1)\n",
    "dx_final = xgb.DMatrix(x_final, enable_categorical=False)\n",
    "# Create a DataFrame with the corresponding IDs\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': df_test['id'].values,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in label_col:\n",
    "    y = df_train[col].values\n",
    "\n",
    "    # Normalize the target\n",
    "    SCALER = StandardScaler()\n",
    "    y = SCALER.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=9450, test_size=0.2)\n",
    "    print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
    "\n",
    "    # Create regression matrices\n",
    "    dtrain_reg = xgb.DMatrix(X_train, y_train, enable_categorical=False)\n",
    "    dval_reg = xgb.DMatrix(X_val, y_val, enable_categorical=False)\n",
    "    \n",
    "    # set hyperparams\n",
    "    params = {\"objective\": \"reg:squarederror\", \"tree_method\": \"gpu_hist\", \"max_depth\":3}\n",
    "    n = 1000\n",
    "\n",
    "    evals = [(dval_reg, \"validation\")]\n",
    "\n",
    "    model = xgb.train(\n",
    "        params=params,\n",
    "        dtrain=dtrain_reg,\n",
    "        num_boost_round=n,\n",
    "        evals=evals,\n",
    "        verbose_eval=5,\n",
    "        # Activate early stopping\n",
    "        early_stopping_rounds=5\n",
    "        )\n",
    "\n",
    "    print(\"*\"*100)\n",
    "    y_train_pred = model.predict(dtrain_reg)\n",
    "    y_train_pred = np.exp(SCALER.inverse_transform(y_train_pred.reshape(-1, 1)))\n",
    "    y_train = np.exp(SCALER.inverse_transform(y_train.reshape(-1, 1)))\n",
    "    print(f\"R2 train {col}: {r2_score(y_train, y_train_pred)}\")\n",
    "    \n",
    "    y_val_pred = model.predict(dval_reg)\n",
    "    y_val_pred = np.exp(SCALER.inverse_transform(y_val_pred.reshape(-1, 1)))\n",
    "    y_val = np.exp(SCALER.inverse_transform(y_val.reshape(-1, 1)))\n",
    "    print(f\"R2 val {col} : {r2_score(y_val, y_val_pred)}\")\n",
    "\n",
    "\n",
    "    y_final = model.predict(dx_final)\n",
    "    y_final = np.exp(SCALER.inverse_transform(y_final.reshape(-1, 1)))\n",
    "    submission_df[col.replace(\"_mean\", \"\")] = y_final\n",
    "    print(\"*\"*100)    \n",
    "    # break\n",
    "# compare with a good submission from kaggle to sanity check\n",
    "sub = pd.read_csv('submission_good.csv')\n",
    "r2_score(sub[sub.columns[1:]], submission_df[sub.columns[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.hist(bins=50, figsize=(10, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure columns are in right order, otherwise you'll get absurd values\n",
    "submission_df[sub.columns].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c planttraits2024 -f submission.csv -m \"Message\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
